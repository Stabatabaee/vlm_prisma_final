{
    "Title": "From the paper’s full text, extract the exact title of the study as published.",
    "Year": "From the publication details, what year did this study appear?",
    "Authors": "List all authors in order as they appear on the paper (e.g., FirstName LastName, FirstName LastName…).",
    "Country / Institution": "Identify the corresponding author’s primary affiliation and country.",
    "Modality": "Which imaging modality or modalities does this study use (e.g., chest X-ray, CT, MRI)?",
    "Dataset(s)": "List each dataset name and its source (e.g., MIMIC-CXR via PhysioNet, IU-Xray from Kaggle).",
    "Cohort Size": "How many images or patients are included in the study dataset?",
    "Image Details": "Describe the image inputs: resolution, views (PA vs. LAT), and any preprocessing (windowing, normalization).",
    "Text Details": "Describe the text inputs: report type (findings only vs. full report), average length, and cleaning steps.",
    "Primary Task": "What is the study’s main task (e.g., report generation, impression summarization, disease classification)?",
    "Pathology Focus": "Which condition(s) are targeted (e.g., pulmonary embolism, pneumothorax, general findings)?",
    "Model Name": "Which Vision–Language Model(s) and version(s) did the authors use (e.g., GPT-4 Turbo Vision, unsloth/Llama-3.2-11B-Vision-Instruct, BLIP-2)? Give the exact name(s) as written in the paper.",
    "Vision Encoder": "Which vision encoder architecture and pretrained weights are used (e.g., ViT-Base, Swin-Transformer)?",
    "Language Decoder": "Which language model backbone and version does the study fine-tune (e.g., GPT-2, Llama-3.2)?",
    "Fusion Strategy": "How are image and text fused—early fusion (pseudo-tokens), late fusion (head), or hybrid cross-attention?",
    "Pretraining Data": "What corpora or datasets were used to pretrain the model before fine-tuning on this task?",
    "Prompt Style": "What prompt format is used—caption-style, chat-style, or structured-instruction?",
    "Optimizer": "Which optimizer and hyperparameters were used (e.g., AdamW with lr=5e-5, weight decay)?",
    "Learning-Rate Schedule": "Describe the learning-rate schedule: warmup steps, decay type (linear, cosine), etc.",
    "Batch Size & Epochs": "What batch size, gradient-accumulation steps, and number of epochs were used?",
    "PEFT / Quantization": "Did the study apply LoRA, prefix-tuning, or quantization (e.g., 4-bit)? Provide details.",
    "Hardware": "Which GPU type/count and precision (fp16, bf16) were employed during training?",
    "Validation Strategy": "What train/validation/test split or cross-validation procedure was used?",
    "NLG Metrics": "Which natural-language metrics were reported (e.g., BLEU, ROUGE-L, METEOR, BERTScore)?",
    "Clinical Metrics": "Which clinical performance metrics were used (e.g., AUC, sensitivity, specificity, F1)?",
    "Human Evaluation": "Was there a human or radiologist evaluation? If so, describe the scoring or qualitative assessment protocol.",
    "Quantitative Results": "List the reported metric values along with their standard deviations or confidence intervals.",
    "Baseline Comparisons": "What performance gains are shown over text-only or image-only baseline models?",
    "Statistical Significance": "Were any statistical tests reported (p-values, paired tests)? If so, what were the results?",
    "Interpretability Method": "Which explainability technique was applied (e.g., SHAP, LIME, attention-map visualization)?",
    "Key Findings": "Summarize the main insights uncovered by the explainability analysis.",
    "Limitations": "What limitations did the authors acknowledge (e.g., small sample size, dataset bias)?",
    "Future Work": "What future research directions or improvements do the authors propose?",
    "Code Availability": "Is code available? If yes, provide the repository link or container (Docker/Singularity).",
    "Data Access": "What is the data access status (public vs. restricted), and are there IRB or consent requirements?"
  }
  